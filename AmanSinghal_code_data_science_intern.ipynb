{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96202012-6de9-4d3e-837c-e769f2a4de12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_recall_fscore_support\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec4f8ab-cef7-4eb7-bb3c-6542d76af563",
   "metadata": {},
   "source": [
    "# 0. Loading Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c070dfc9-9aff-4eee-94ad-12ffed3f1ccc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.22.3)\n",
      "Collecting tzdata>=2022.1\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.0.0 tzdata-2023.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting scikit-learn\n",
      "  Downloading scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.22.3)\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scipy>=1.3.2\n",
      "  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.2.0 scikit-learn-1.2.2 scipy-1.10.1 threadpoolctl-3.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge) (1.16.0)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install galai\n",
    "!pip install pandas\n",
    "!pip install -U scikit-learn\n",
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d4ff23b-8a09-4297-9207-4aa91f03ee5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install sentencepiece\n",
    "# !pip install accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32672ec-8b50-490f-91c8-def5dc4bf029",
   "metadata": {},
   "source": [
    "### 0.1 Reading JSON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12250c51-1b8c-43ce-8470-33f48b8f4d43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('questions_file.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f09fc52c-dd46-41e7-a8fc-4c39ad418304",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape is (200, 2) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>Four friends ordered four pizzas for a total o...</td>\n",
       "      <td>The other two pizzas cost 64-30 = &lt;&lt;64-30=34&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Jake is walking through the Museum of Entomolo...</td>\n",
       "      <td>First find the total number of spider legs: 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>Frankie and Binkie went bowling together.  Fra...</td>\n",
       "      <td>Twice Binkie's score is 2*90=&lt;&lt;2*90=180&gt;&gt;180....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>Ali is a dean of a private school where he tea...</td>\n",
       "      <td>Each of John’s classes has a capacity of 120 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>Carrie is planning the caroling schedule. The ...</td>\n",
       "      <td>First find the total time the choir spends si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question   \n",
       "781   Four friends ordered four pizzas for a total o...  \\\n",
       "171   Jake is walking through the Museum of Entomolo...   \n",
       "1081  Frankie and Binkie went bowling together.  Fra...   \n",
       "1212  Ali is a dean of a private school where he tea...   \n",
       "797   Carrie is planning the caroling schedule. The ...   \n",
       "\n",
       "                                           ground_truth  \n",
       "781    The other two pizzas cost 64-30 = <<64-30=34>...  \n",
       "171    First find the total number of spider legs: 8...  \n",
       "1081   Twice Binkie's score is 2*90=<<2*90=180>>180....  \n",
       "1212   Each of John’s classes has a capacity of 120 ...  \n",
       "797    First find the total time the choir spends si...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd = pd.DataFrame(data)\n",
    "print (\"Data shape is\", data_pd.shape, \"\\n\")\n",
    "data_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de668291-e4c8-4047-bf92-b4373d384f5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dictionary to lists for inference \n",
    "questions = list(data[\"question\"].values())\n",
    "ground_truth = list(data[\"ground_truth\"].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27f9d537-9148-4e74-ad29-3769c163a192",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final answers are INTEGERS between 2 & 224000\n"
     ]
    }
   ],
   "source": [
    "# All answers are integers \n",
    "final_answers = [int(ground_truth[i].split(\"\\n\")[-1].split(\":\")[-1]) for i in range(len(ground_truth))]\n",
    "print (\"The final answers are INTEGERS between\", min(final_answers), \"&\", max(final_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2171f59f-2ecd-4518-897d-4ccd940ad4a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39c6702a-76aa-4a98-8c8c-ed55ae68871e",
   "metadata": {},
   "source": [
    "### 0.2 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c8fa0cd-df4c-4205-888f-e0e2cbd67861",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove whitespaces\n",
    "    text = text.strip()\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3da12813-cdd1-4ce2-9f81-c6ab5d35e9eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre_questions = [preprocess_text(questions[i]) for i in range(len(questions))]\n",
    "pre_ground_truth = [preprocess_text(ground_truth[i]) for i in range(len(ground_truth))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c5cddf7-f0a8-4359-96b5-2dc646628abf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Question: Four friends ordered four pizzas for a total of 64 dollars. If two of the pizzas cost 30 dollars, how much did each of the other two pizzas cost if they cost the same amount? \n",
      "\n",
      "Pre-Processed Question: four friends ordered four pizzas for a total of 64 dollars. if two of the pizzas cost 30 dollars, how much did each of the other two pizzas cost if they cost the same amount? \n",
      "\n",
      "Original Ground Truth:  The other two pizzas cost 64-30 = <<64-30=34>>34 dollars.\n",
      "Each of the other two pizzas cost 34/2 = <<34/2=17>>17 dollars each.\n",
      "A: 17 \n",
      "\n",
      "Pre-Processed Ground Truth: the other two pizzas cost 64-30 = <<64-30=34>>34 dollars. each of the other two pizzas cost 34/2 = <<34/2=17>>17 dollars each. a: 17 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Question:\", questions[0],\"\\n\")\n",
    "print(\"Pre-Processed Question:\", pre_questions[0],\"\\n\")\n",
    "\n",
    "print(\"Original Ground Truth:\", ground_truth[0],\"\\n\")\n",
    "print(\"Pre-Processed Ground Truth:\", pre_ground_truth[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4489dd-4610-4ef0-8886-61ef1590b7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e394e85-7450-48ec-a9d3-02767096970c",
   "metadata": {},
   "source": [
    "### 0.3 Univariate Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9dcf3cc-df39-4abc-a67d-99f1abd22f9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_words(sentence):\n",
    "    return len(sentence.split())\n",
    "\n",
    "def find_max_words(sentences_list):\n",
    "    max_words = 0\n",
    "    for sentence in sentences_list:\n",
    "        word_count = count_words(sentence)\n",
    "        if word_count > max_words:\n",
    "            max_words = word_count\n",
    "    return max_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9e560c5-e928-4f01-9387-49db2a2c275a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Maximum questions and answer size\n",
    "find_max_words(pre_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcb17708-5f4c-4f1b-8a59-b21353c7531c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_max_words(pre_ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c955a5c-158c-4ae7-8e30-99d240b12da1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b42275e3-ed64-4a8c-a3a7-16c57d3a9e78",
   "metadata": {},
   "source": [
    "### 0.4 Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ac3c5e5-e0cf-48c6-a9a8-a76488979c5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_rouge(predicted_answers, reference_answers):\n",
    "    # ROUGE-L\n",
    "    rouge = Rouge()\n",
    "    rouge_scores = rouge.get_scores(predicted_answers, reference_answers, avg=True)\n",
    "    rouge_l = rouge_scores['rouge-l']['f']\n",
    "    return rouge_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7dca7a0-faf6-456f-827e-241c0ce7f4c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(predicted_answers, reference_answers):\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(reference_answers, predicted_answers)\n",
    "\n",
    "    # Precision, Recall, F1 Score\n",
    "    _, _, f1, _ = precision_recall_fscore_support(reference_answers, predicted_answers, average='weighted', zero_division=0)\n",
    "    \n",
    "    # Mean Reciprocal Rank (MRR)\n",
    "    mrr = 0\n",
    "    for i, (predicted, reference) in enumerate(zip(predicted_answers, reference_answers)):\n",
    "        if predicted == reference:\n",
    "            mrr += 1 / (i + 1)\n",
    "    mrr /= len(predicted_answers)\n",
    "    return accuracy, f1, mrr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae6d903-0e45-4b9c-b46a-106c12128cdc",
   "metadata": {},
   "source": [
    "# 1. GPT NEO - 350 M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ff9adc37-6dad-4f45-8612-137a501d2b7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "13f6a545-164a-4cf5-a302-0bbf9491b045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GPTNeoForCausalLM.from_pretrained(\"xhyi/PT_GPTNEO350_ATG\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"xhyi/PT_GPTNEO350_ATG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424914e2-7881-4b42-ae7e-17954804fcf8",
   "metadata": {},
   "source": [
    "### 1.1 Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "705fb250-8791-441f-8701-da6f6accfff9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function to generate a response\n",
    "def generate_response(question):\n",
    "    input_text = f\"question: {question}\"\n",
    "    input_tokens = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate the output tokens\n",
    "    output_tokens = model.generate(input_tokens, max_length=100, num_return_sequences=1)\n",
    "    response_text = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0a786a4b-0272-4ecd-bb14-6e44e34c0da2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answers = []\n",
    "for question in tqdm.tqdm(questions):\n",
    "    answer = generate_response(question)\n",
    "    answer = preprocess_text(answer.split(\"\\nA:\")[-1])\n",
    "    answers.append(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37865229-a18c-4f14-ab96-20951eeb9763",
   "metadata": {},
   "source": [
    "### 1.2 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "364f1ea1-c581-435e-a807-c9b58a0a8a17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rouge_l = calculate_rouge(answers, pre_ground_truth)\n",
    "print(\"ROUGE-L:\", rouge_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae72cbf7-7b51-4a82-82ec-cab58b9bcff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec750ad2-f81c-427d-9756-9cf53e5b8773",
   "metadata": {},
   "source": [
    "# 2. Google Flan-T5-Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f1d238b-f445-4950-a806-2f091802d59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f856ce8-2542-4e3a-9593-bf0102c88119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ce35e4d2e54e6096eba31914a2df89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f999d58c6f743c39f7b7342df0c7786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e4d24bf33745e3a2f9d714e8a00adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb09e1c7daf9406f990c82f50e3de546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8ed3b57-8133-41d8-a4f8-d99612244bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634df26b-dc09-4b9e-b47e-b86f920282f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd3fc850-cad6-4809-9f57-e04f97e399e2",
   "metadata": {},
   "source": [
    "### 2.1 Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f037b63f-9758-4587-96cd-305edfc2f87b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function to generate a response\n",
    "def generate_response(question):\n",
    "    input_text = f\"question: {question}\"\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "    # Generate the output tokens\n",
    "    output_tokens = model.generate(input_ids, max_length=100, num_return_sequences=1)\n",
    "    response_text = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37c5ad2f-1acf-4221-bb23-37551a0e119a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:18<00:00,  1.45it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "for question in tqdm.tqdm(pre_questions):\n",
    "    pred_label = generate_response(question)\n",
    "    preds.append(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2819e881-8cec-49f3-b751-1883a77a7e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The first pizza cost 64 - 30 = $36. The second pizza cost 36 - 30 = $36. The third pizza cost 36 - 30 = $36. The fourth pizza cost 36 - 36 = $36. The other two pizzas cost 36 - 36 = $36. The other two pizzas cost 36 - 36 = $36. The other two pizzas cost 36 - 36 = $36. The other two pizzas cost 36 -'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0] # Not able to perform mathematical calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6a31da-5c82-42ec-b99c-804ca07c0844",
   "metadata": {},
   "source": [
    "### 2.2 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ab8457d-003e-4950-a346-4afbec11cfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "F1 Score: 0.0\n",
      "Mean Reciprocal Rank (MRR): 0.0\n"
     ]
    }
   ],
   "source": [
    "accuracy, f1, mrr = calculate_metrics(preds, pre_ground_truth)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Mean Reciprocal Rank (MRR):\", mrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d619404-d37a-40dd-a02e-bd20d7403bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-L: 0.25710498885709737\n"
     ]
    }
   ],
   "source": [
    "rouge_l = calculate_rouge(preds, pre_ground_truth)\n",
    "print(\"ROUGE-L:\", rouge_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b3382f-46f6-472d-9044-bd86d49a644f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7953d65e-2032-4659-9831-66343b889a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c600310f-966b-479c-8827-373e7bc73af9",
   "metadata": {},
   "source": [
    "# 3. Google Flan-T5-XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "747c2cf3-6e32-41c8-b5ce-d8e5665f0565",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3adb3e28-fae1-4d3c-9787-3bd249e1aa9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e62de93f89594d1a844ef1f1f504edf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xl\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-xl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f740fdd7-7768-48d0-8111-331f4f6b772a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d2d130-756a-471e-a8ed-5d5924bfb0a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92d169c2-ced3-47f9-9ea7-53b214f4d3c2",
   "metadata": {},
   "source": [
    "### 3.1 Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "486cb762-d95d-41c5-9a22-5c6ddb048d16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function to generate a response\n",
    "def generate_step_by_step_response(question):\n",
    "    input_text = f\"Answer the following mathematical word problem by reasoning step-by-step: {question}\"\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "    # Generate the output tokens\n",
    "    output_tokens = model.generate(input_ids, max_length=100, num_return_sequences=1)\n",
    "    response_text = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d69245f-2c9a-4e7d-857b-e3e7dc0aacf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:11<00:00,  2.80it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "for question in tqdm.tqdm(pre_questions):\n",
    "    pred_label = generate_response(question)\n",
    "    preds.append(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ae2e6439-6281-4307-b1b2-5ed3180633e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.01\n",
      "F1 Score: 0.013333333333333332\n",
      "Mean Reciprocal Rank (MRR): 0.00013938466768655448\n"
     ]
    }
   ],
   "source": [
    "accuracy, f1, mrr = calculate_metrics(preds, [str(i) for i in final_answers])\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Mean Reciprocal Rank (MRR):\", mrr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7841f62f-5726-4032-b3bb-ade5be7e2092",
   "metadata": {},
   "source": [
    "### 3.2 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3f497762-0f70-4e24-9427-261dc8e87277",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [05:54<00:00,  1.77s/it]\n"
     ]
    }
   ],
   "source": [
    "long_preds = []\n",
    "for question in tqdm.tqdm(pre_questions):\n",
    "    pred_label = generate_step_by_step_response(question)\n",
    "    long_preds.append(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eb879607-065f-4ee5-b037-91f3e68e2d37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-L: 0.39259634785986214\n"
     ]
    }
   ],
   "source": [
    "rouge_l = calculate_rouge(long_preds, pre_ground_truth)\n",
    "print(\"ROUGE-L:\", rouge_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a0adfd-2fee-4605-a521-a38c3429aa91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f1f9c0c-1071-4985-9a65-4b2c42e22715",
   "metadata": {},
   "source": [
    "# B. Prompting Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b3150a-e269-4205-bc6c-3f4975249bb8",
   "metadata": {},
   "source": [
    "### 4.1 Prompt 1 - CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9485cdaa-168d-4243-be9e-8d794edfd6a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nuse the first “reasoning” prompt\\nto extract a full reasoning path from a language model, and then use the second “answer” prompt to\\nextract the answer in the correct format from the reasoning text\\n'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "use the first “reasoning” prompt\n",
    "to extract a full reasoning path from a language model, and then use the second “answer” prompt to\n",
    "extract the answer in the correct format from the reasoning text\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "29d9f1bb-6483-4cec-84aa-783543df1a10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function to generate a response\n",
    "def prompt_1(question):\n",
    "    input_text = f\"Q: {question} \\n A: Let's think step by step\"\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "    # Generate the output tokens\n",
    "    output_tokens = model.generate(input_ids, max_length=100, num_return_sequences=1)\n",
    "    response_text = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3a80b894-3616-4670-a7db-e85435f542a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function to generate a response\n",
    "def prompt_1_extraction(question, prompt_1_ans):\n",
    "    input_text = f\"Q: {question} \\n A: Let's think step by step {prompt_1_ans} Therefore, the answer (arabic numerals) is\"\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "    # Generate the output tokens\n",
    "    output_tokens = model.generate(input_ids, max_length=100, num_return_sequences=1)\n",
    "    response_text = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cab37845-c343-4606-af8d-6978b09ab87f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [05:26<00:00,  1.63s/it]\n"
     ]
    }
   ],
   "source": [
    "preds_prompt_1 = []\n",
    "for question in tqdm.tqdm(pre_questions):\n",
    "    pred_label = prompt_1(question)\n",
    "    preds_prompt_1.append(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "71ca179a-8b2a-4622-8900-8bd59156653e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:43<00:00,  4.55it/s]\n"
     ]
    }
   ],
   "source": [
    "preds_prompt_1_extrct = []\n",
    "for i in tqdm.tqdm(range(len(pre_questions))):\n",
    "    question = pre_questions[i]\n",
    "    prompt_1_ans = preds_prompt_1[i]\n",
    "    pred_label = prompt_1_extraction(question, prompt_1_ans)\n",
    "    preds_prompt_1_extrct.append(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0694ab8f-1586-434b-8b7c-d58d02564a49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22ea9e2e-448a-4aed-a869-51fb60df51d3",
   "metadata": {},
   "source": [
    "### 4.1.1 Prompt 1 - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "12e7da44-2713-4b05-abc5-442d00ca02e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-L: 0.39106372368937337\n"
     ]
    }
   ],
   "source": [
    "rouge_l = calculate_rouge(preds_prompt_1, pre_ground_truth)\n",
    "print(\"ROUGE-L:\", rouge_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "88a01591-09fe-421e-9ac2-3681c2a9c770",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.105\n",
      "F1 Score: 0.11126984126984127\n",
      "Mean Reciprocal Rank (MRR): 0.0012522336645191129\n"
     ]
    }
   ],
   "source": [
    "accuracy, f1, mrr = calculate_metrics(preds_prompt_1_extrct, [str(i) for i in final_answers])\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Mean Reciprocal Rank (MRR):\", mrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d38f9c-8e07-4151-ba8f-5d8ac358aa26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a457e685-4020-463b-b648-2ec426de5483",
   "metadata": {},
   "source": [
    "### 4.2 Prompt 2 - CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2fc6f05a-786d-48a0-9d3d-b4230f32bf4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function to generate a response\n",
    "def prompt_2(question):\n",
    "    input_text = f\"Question: {question} \\n A: Let's think step by step\"\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "    # Generate the output tokens\n",
    "    output_tokens = model.generate(input_ids, max_length=100, num_return_sequences=1)\n",
    "    response_text = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8cb925e8-977d-4b2c-92c8-f4e190428ecb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function to generate a response\n",
    "def prompt_2_extraction(question, prompt_1_ans):\n",
    "    input_text = f\"Question: {question} \\n A: Let's think step by step {prompt_1_ans} Therefore, the answer (arabic numerals) is\"\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "    # Generate the output tokens\n",
    "    output_tokens = model.generate(input_ids, max_length=100, num_return_sequences=1)\n",
    "    response_text = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5190313e-c247-4edd-8ec6-74c6274abcff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [05:27<00:00,  1.64s/it]\n"
     ]
    }
   ],
   "source": [
    "preds_prompt_2 = []\n",
    "for question in tqdm.tqdm(pre_questions):\n",
    "    pred_label = prompt_2(question)\n",
    "    preds_prompt_2.append(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cb5ccd81-da19-4e6f-b1fc-16c0c11ac6cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:46<00:00,  4.33it/s]\n"
     ]
    }
   ],
   "source": [
    "preds_prompt_2_extrct = []\n",
    "for i in tqdm.tqdm(range(len(pre_questions))):\n",
    "    question = pre_questions[i]\n",
    "    prompt_2_ans = preds_prompt_2[i]\n",
    "    pred_label = prompt_2_extraction(question, prompt_2_ans)\n",
    "    preds_prompt_2_extrct.append(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0359ccee-bdcb-4f89-9398-07b30e1e0452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b540d31e-9d49-4676-848d-0892b6ab391e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.2.1 Prompt 2 - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6de571d7-302b-4859-9b20-f7114715de1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-L: 0.38860299268097004\n"
     ]
    }
   ],
   "source": [
    "rouge_l = calculate_rouge(preds_prompt_2, pre_ground_truth)\n",
    "print(\"ROUGE-L:\", rouge_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "40744223-e4a7-47e1-90e1-3ddc9a269feb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.11\n",
      "F1 Score: 0.11789069264069264\n",
      "Mean Reciprocal Rank (MRR): 0.0016622039690888627\n"
     ]
    }
   ],
   "source": [
    "accuracy, f1, mrr = calculate_metrics(preds_prompt_2_extrct, [str(i) for i in final_answers])\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Mean Reciprocal Rank (MRR):\", mrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2981cce5-c2e8-4ead-8203-bd375036f9de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c90c4728-2c3c-45cd-9b14-4fb798ba8032",
   "metadata": {},
   "source": [
    "### 4.3 Prompt 3 - PoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1e7851b5-7c7d-4700-9689-60d6fa905755",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_numerical_vals(text):\n",
    "    integer_values = re.findall(r'\\d+', text)\n",
    "    return int(integer_values[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7936e865-2cac-4a4e-910d-0dad10c01588",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function to generate a response\n",
    "def prompt_3(question):\n",
    "    input_text = f\"# Question: {question} # Answer the question by implementing a solver() function \\n def solver(): \\n #Let's write a Python program step by step, and then return the answer\"\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "    # Generate the output tokens\n",
    "    output_tokens = model.generate(input_ids, max_length=100, num_return_sequences=1)\n",
    "    response_text = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a49e0b4e-4419-4730-9da5-04b534492464",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [08:16<00:00,  2.48s/it]\n"
     ]
    }
   ],
   "source": [
    "preds_prompt_3 = []\n",
    "for question in tqdm.tqdm(pre_questions):\n",
    "    pred_label = prompt_3(question)\n",
    "    preds_prompt_3.append(pred_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfd716a-4dbe-4c33-a200-94d475e71153",
   "metadata": {},
   "source": [
    "### 4.3.1 Prompt 3 - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4d98391b-1e4e-4a75-95aa-f3d968a5fa29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-L: 0.13898508263213807\n"
     ]
    }
   ],
   "source": [
    "rouge_l = calculate_rouge(preds_prompt_3, pre_ground_truth)\n",
    "print(\"ROUGE-L:\", rouge_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a4b5149a-81b8-41cf-b944-ed30b16abee9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds_prompt_3_extrct = [extract_numerical_vals(i) for i in preds_prompt_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4a7bf797-88d6-469c-88bf-e848569fae6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.015\n",
      "F1 Score: 0.012721804511278197\n",
      "Mean Reciprocal Rank (MRR): 0.0006328586651167296\n"
     ]
    }
   ],
   "source": [
    "accuracy, f1, mrr = calculate_metrics([str(i) for i in preds_prompt_3_extrct], [str(i) for i in final_answers])\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Mean Reciprocal Rank (MRR):\", mrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c281da9a-308f-40b8-affd-e42b3846ea64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b864e01-2a3a-44db-ac30-9390c2eb47a1",
   "metadata": {},
   "source": [
    "### 4.4.1 Prompt 4 - Target Audience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "562285af-47ca-4c4c-a58e-0629d2ef9c91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_numerical_vals(text):\n",
    "    integer_values = re.findall(r'\\d+', text)\n",
    "    return int(integer_values[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "46089422-7038-4680-abea-773422ffd15e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function to generate a response\n",
    "def prompt_4(question):\n",
    "    input_text = f\"# Describe the solution of this question to a 6-year-old. {question}\"\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "    # Generate the output tokens\n",
    "    output_tokens = model.generate(input_ids, max_length=100, num_return_sequences=1)\n",
    "    response_text = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fac352e2-b2b8-4f88-912f-b4225e7fc7b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:58<00:00,  1.69it/s]\n"
     ]
    }
   ],
   "source": [
    "preds_prompt_4 = []\n",
    "for question in tqdm.tqdm(pre_questions):\n",
    "    pred_label = prompt_4(question)\n",
    "    preds_prompt_4.append(pred_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f849064f-fc81-4c1e-af1e-db38f3deb014",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.4.1 Prompt 4 - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "14925c2a-d46d-4daa-a11b-fdc79ee9d99b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-L: 0.20343307172080788\n"
     ]
    }
   ],
   "source": [
    "rouge_l = calculate_rouge(preds_prompt_4, pre_ground_truth)\n",
    "print(\"ROUGE-L:\", rouge_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "dc0bc45f-07fb-4886-b174-5ccce0255a2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds_prompt_4_extrct = [extract_numerical_vals(i) for i in preds_prompt_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f7fa6467-1243-44b2-877a-cccfd79d33b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.055\n",
      "F1 Score: 0.0473997113997114\n",
      "Mean Reciprocal Rank (MRR): 0.0007705984319997839\n"
     ]
    }
   ],
   "source": [
    "accuracy, f1, mrr = calculate_metrics(preds_prompt_4_extrct, final_answers)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Mean Reciprocal Rank (MRR):\", mrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50186363-ab49-4f5e-b723-bb2384090298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c342764-99ce-4f50-bbd4-7a216974f3da",
   "metadata": {},
   "source": [
    "# 5. Facebook Galactica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a73df803-c532-406d-a6cb-1bb289724481",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting galai\n",
      "  Downloading galai-1.1.6.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.12 in /opt/conda/lib/python3.10/site-packages (from galai) (1.13.1)\n",
      "Collecting transformers==4.25.1\n",
      "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tokenizers in /opt/conda/lib/python3.10/site-packages (from galai) (0.13.3)\n",
      "Collecting parallelformers==1.2.7\n",
      "  Downloading parallelformers-1.2.7.tar.gz (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from galai) (0.18.0)\n",
      "Collecting markdown>=3.4\n",
      "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting bleach[css]~=5.0.1\n",
      "  Downloading bleach-5.0.1-py3-none-any.whl (160 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.9/160.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from galai) (5.9.0)\n",
      "Collecting dacite\n",
      "  Downloading dacite-1.8.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.25.1->galai) (1.22.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.25.1->galai) (23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.25.1->galai) (2023.3.23)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.25.1->galai) (0.13.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages/PyYAML-6.0-py3.10-linux-x86_64.egg (from transformers==4.25.1->galai) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.25.1->galai) (4.64.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.25.1->galai) (2.28.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.25.1->galai) (3.6.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from bleach[css]~=5.0.1->galai) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach[css]~=5.0.1->galai) (0.5.1)\n",
      "Collecting tinycss2<1.2,>=1.1.0\n",
      "  Downloading tinycss2-1.1.1-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->galai) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.25.1->galai) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.25.1->galai) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.25.1->galai) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.25.1->galai) (2022.9.24)\n",
      "Building wheels for collected packages: galai, parallelformers\n",
      "  Building wheel for galai (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for galai: filename=galai-1.1.6-py3-none-any.whl size=24732 sha256=29c2db5db22a5514c757c93dbaf1e2ffe95210c0a292f6602eec88e7d8a49635\n",
      "  Stored in directory: /root/.cache/pip/wheels/dd/40/e3/98d8831ea3461fe89569f8fe52b0b9bdb6d97b08e75305820f\n",
      "  Building wheel for parallelformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for parallelformers: filename=parallelformers-1.2.7-py3-none-any.whl size=117771 sha256=a7dfa1440ec8f34a41f3205a0ab3bf3bee9670cb6f9e436745f33dd8564860b2\n",
      "  Stored in directory: /root/.cache/pip/wheels/f0/3f/f9/a241340d715a8935f9d89b7e45f187a78c5cb1854a1fc9ebaf\n",
      "Successfully built galai parallelformers\n",
      "Installing collected packages: tinycss2, markdown, dacite, bleach, transformers, parallelformers, galai\n",
      "  Attempting uninstall: tinycss2\n",
      "    Found existing installation: tinycss2 1.2.1\n",
      "    Uninstalling tinycss2-1.2.1:\n",
      "      Successfully uninstalled tinycss2-1.2.1\n",
      "  Attempting uninstall: bleach\n",
      "    Found existing installation: bleach 6.0.0\n",
      "    Uninstalling bleach-6.0.0:\n",
      "      Successfully uninstalled bleach-6.0.0\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.28.0\n",
      "    Uninstalling transformers-4.28.0:\n",
      "      Successfully uninstalled transformers-4.28.0\n",
      "Successfully installed bleach-5.0.1 dacite-1.8.0 galai-1.1.6 markdown-3.4.3 parallelformers-1.2.7 tinycss2-1.1.1 transformers-4.25.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install galai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2874386-8589-400d-baf3-a926d8e1e411",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import galai as gal\n",
    "from galai.notebook_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "711849f7-78df-4eed-a6f0-a69c20287e4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "706a1eb5bd744ea5bef719a3936e4110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/166 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e0795176f4448d8507626d39589216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.14M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf73e62cc114a91b1f4c80ded533678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/3.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0d2642d827446390b88687d34198ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d83279d74a6e405e9c5eabe1bec9a29e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)model.bin.index.json:   0%|          | 0.00/45.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec7108e2eaf491eb95b0206a5b70ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00001-of-00002.bin:   0%|          | 0.00/9.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c05dc684474d849b42ff0c02e9f17b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00002-of-00002.bin:   0%|          | 0.00/3.77G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = gal.load_model(\"standard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fb0e3fb-a645-4b1f-ba9a-95f430e4eb41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Do some experiments with 1-2 sentences and then run them for all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90e4a307-bc72-4701-85e7-340406c27042",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prompt = f\"Question: A bat and a ball cost $\\\\$1.10$ in total. The bat costs $\\\\$1.00$ more than the ball. How much does the ball cost?\\n\\n<work>\"\n",
    "# display_markdown(model.generate(prompt, new_doc=True, max_new_tokens=250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49fcd72-cbe6-49a6-b843-cc404760a44d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
